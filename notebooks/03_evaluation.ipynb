{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d400e56-77c7-417e-a325-4137c347423b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\fouad\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.keras.wrappers'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 31\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Adam\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m EarlyStopping, ModelCheckpoint\n\u001b[1;32m---> 31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwrappers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mscikit_learn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m KerasClassifier\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Add custom modules\u001b[39;00m\n\u001b[0;32m     34\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../src\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.keras.wrappers'"
     ]
    }
   ],
   "source": [
    "# ====================================================================================================\n",
    "# CELL 1: Imports & Setup\n",
    "# ====================================================================================================\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Machine Learning Libraries\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (classification_report, confusion_matrix, \n",
    "                           accuracy_score, precision_score, recall_score, f1_score,\n",
    "                           roc_auc_score, roc_curve)\n",
    "\n",
    "# Deep Learning Libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "# Add custom modules\n",
    "sys.path.append('../src')\n",
    "from preprocess import load_and_preprocess_data\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Define paths\n",
    "DATA_PATH = \"../data/UNSW-NB15_full.csv\"  # Your preprocessed dataset\n",
    "MODELS_PATH = \"../models/\"\n",
    "RESULTS_PATH = \"../results/\"\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs(MODELS_PATH, exist_ok=True)\n",
    "os.makedirs(RESULTS_PATH, exist_ok=True)\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU Available: {len(tf.config.list_physical_devices('GPU')) > 0}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf002c95-a8f6-4ec9-87e9-9853c9c3a080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading preprocessed UNSW-NB15 dataset...\n",
      "==================================================\n",
      "‚ùå Error loading data: name 'load_and_preprocess_data' is not defined\n"
     ]
    }
   ],
   "source": [
    "# ====================================================================================================\n",
    "# CELL 2: Load Data\n",
    "# ====================================================================================================\n",
    "\n",
    "print(\"Loading preprocessed UNSW-NB15 dataset...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# üëâ DECISION: Choose task type\n",
    "TASK_TYPE = \"binary\"  # Change to \"multiclass\" for attack category classification\n",
    "\n",
    "# Load preprocessed data\n",
    "try:\n",
    "    X_processed, y, preprocessor = load_and_preprocess_data(DATA_PATH, task=TASK_TYPE)\n",
    "    \n",
    "    print(f\"‚úÖ Dataset loaded successfully!\")\n",
    "    print(f\"Features shape: {X_processed.shape}\")\n",
    "    print(f\"Target shape: {y.shape}\")\n",
    "    \n",
    "    # Class distribution\n",
    "    if TASK_TYPE == \"binary\":\n",
    "        print(f\"\\nBinary Classification Target Distribution:\")\n",
    "        print(f\"Benign (0): {sum(y == 0)}\")\n",
    "        print(f\"Attack (1): {sum(y == 1)}\")\n",
    "        print(f\"Attack percentage: {sum(y == 1) / len(y) * 100:.2f}%\")\n",
    "    else:\n",
    "        print(f\"\\nMulticlass Target Distribution:\")\n",
    "        print(y.value_counts())\n",
    "        \n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå Preprocessed dataset not found!\")\n",
    "    print(\"Please run data preprocessing first or check the file path.\")\n",
    "    print(\"Expected file: UNSW-NB15_full.csv\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading data: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50955942-3855-4018-92b0-f76ca372d0a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
